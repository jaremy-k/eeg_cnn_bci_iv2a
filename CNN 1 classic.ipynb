{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e68949f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score\n",
    "from mne.decoding import CSP\n",
    "from glob import glob\n",
    "from scipy.signal import welch\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.utils.data as data_utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import show\n",
    "from bokeh.models import LinearAxis, Range1d\n",
    "\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "import scipy.io\n",
    "import torch.utils.data as Data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d2eb6151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCICIV_2a_gdf/A01T.gdf\n",
      "Extracting EDF parameters from /Users/germankucheravenko/Documents/Магистратура «Технологии интеграции данных и приложений»/Проекты/EEG/EEGNet-master/BCICIV_2a_gdf/A01T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 672527  =      0.000 ...  2690.108 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/mne/io/edf/edf.py:1123: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  etmode = np.fromstring(etmode, UINT8).tolist()[0]\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     0      0      5]\n",
      " [     0      0      3]\n",
      " [ 29683      0      5]\n",
      " ...\n",
      " [670550      0      6]\n",
      " [670550      0      1]\n",
      " [671050      0      7]]\n",
      "{'1023': 1, '1072': 2, '276': 3, '277': 4, '32766': 5, '768': 6, '769': 7, '770': 8, '771': 9, '772': 10}\n",
      "{'left': 7, 'right': 8, 'foot': 9, 'tongue': 10}\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "Using data from preloaded Raw for 288 events and 1250 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(288, 22, 1250)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_score = []\n",
    "name = []\n",
    "i = 1\n",
    "fname = 'BCICIV_2a_gdf/A0'+str(i)+'T.gdf'\n",
    "print(fname)\n",
    "# path = \"BCICIV_2a_gdf/\"\n",
    "# filename = \"A01T\"\n",
    "\n",
    "raw = mne.io.read_raw_gdf(fname, eog=['EOG-left', 'EOG-central', 'EOG-right'], preload = True)\n",
    "raw.drop_channels(['EOG-left', 'EOG-central', 'EOG-right'])\n",
    "\n",
    "mapping={\n",
    "'EEG-Fz' : 'Fz',\n",
    "'EEG-0' : 'FC3',\n",
    "'EEG-1' : 'FC1',\n",
    "'EEG-2' : 'FCz',\n",
    "'EEG-3' : 'FC2',\n",
    "'EEG-4' : 'FC4',\n",
    "'EEG-5' : 'C5',\n",
    "'EEG-C3' : 'C3',\n",
    "'EEG-6' : 'C1',\n",
    "'EEG-Cz' : 'Cz',\n",
    "'EEG-7' : 'C2',\n",
    "'EEG-C4' : 'C4',\n",
    "'EEG-8' : 'C6',\n",
    "'EEG-9' : 'CP3',\n",
    "'EEG-10' : 'CP1',\n",
    "'EEG-11' : 'CPz',\n",
    "'EEG-12' : 'CP2',\n",
    "'EEG-13' : 'CP4',\n",
    "'EEG-14' : 'P1',\n",
    "'EEG-Pz' : 'Pz',\n",
    "'EEG-15' : 'P2',\n",
    "'EEG-16' : 'POz',\n",
    "}\n",
    "\n",
    "raw.rename_channels(mapping)\n",
    "montage = mne.channels.make_standard_montage('standard_1020')\n",
    "raw.set_montage(montage, on_missing='warn')\n",
    "picks = mne.pick_types(raw.info,eeg=True)\n",
    "raw.filter(8,35, picks=picks, method='iir', n_jobs=1, iir_params=dict(order=5, ftype='butter', output='sos'), verbose=False)\n",
    "\n",
    "evetnt_id = {}\n",
    "if fname == 'BCICIV_2a_gdf/A04T.gdf':\n",
    "    event_id = dict(left=5, right=6, foot=7, tongue=8)\n",
    "    event_id_rest = dict(left_rest=5, right_rest=6, foot_rest=7, tongue_rest=8)\n",
    "else:\n",
    "    event_id = dict(left=7, right=8, foot=9, tongue=10)\n",
    "    event_id_rest = dict(left_rest=7, right_rest=8, foot_rest=9, tongue_rest=10)\n",
    "# picks = mne.pick_types(raw.info,eeg=True)\n",
    "events, t = mne.events_from_annotations(raw, verbose=False)\n",
    "print(events)\n",
    "print(t)\n",
    "print(event_id)\n",
    "# events = events[events[:,2] == 7]\n",
    "# i = 0\n",
    "tmin = 0.3 # minmax[0:,0][i-1]\n",
    "tmax = 5.295 # minmax[0:,1][i-1]\n",
    "\n",
    "epochs = mne.Epochs(raw, events, event_id, tmin=tmin, tmax=tmax, proj=False, picks=picks, baseline=None, preload=True)\n",
    "# epochs = mne.Epochs(raw, events, {'during' : 1}, -2, -0.5, proj=False,\n",
    "#                     picks=picks, baseline=None, preload=True, verbose=False)\n",
    "# print(epochs)\n",
    "epochs_train = epochs.copy()\n",
    "# print(epochs_train)\n",
    "y = epochs.events[:, -1]\n",
    "# print('y', y, y.shape)\n",
    "X = epochs.get_data()\n",
    "# print('x', X, X.shape)\n",
    "X.shape\n",
    "\n",
    "\n",
    "# evoked_0.plot_joint()\n",
    "# evoked_1.plot_joint()\n",
    "# evoked_2.plot_joint()\n",
    "# evoked_3.plot_joint()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "7b9e57bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 22, 1250)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = X.astype('float32')\n",
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "85360d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = X.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e338ce73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xget = np.random.rand(288, 22, 1250).astype('float32') # np.random.rand generates between [0, 1)\n",
    "# yget = np.round(np.random.rand(288)) # binary data, so we round it to 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b3d4ef06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(216, 22, 1250) (216,)\n",
      "torch.Size([216, 22, 1250])\n",
      "torch.Size([72, 22, 1250])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X1, y1)\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "trans_train = transforms.Compose([transforms.ToTensor()]) # , transforms.Normalize(1.6767584353936251e-09, 5.070522318910306e-06)])\n",
    "trans_test = transforms.Compose([transforms.ToTensor()]) # , transforms.Normalize(1.9543e-10, 1.1041e-06)])\n",
    "\n",
    "\n",
    "inputs_train  = torch.tensor(X_train)\n",
    "print(inputs_train.shape)\n",
    "targets_train = torch.IntTensor(y_train)\n",
    "\n",
    "dataset_train = TensorDataset(inputs_train, targets_train)\n",
    "train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "inputs_test  = torch.tensor(X_test)\n",
    "print(inputs_test.shape)\n",
    "targets_test = torch.IntTensor(y_test)\n",
    "\n",
    "dataset_test = TensorDataset(inputs_test, targets_test)\n",
    "test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d303c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv1d(22, 22, kernel_size=(200,), stride=(1,), padding=(1,))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv1d(22, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv1d(32, 48, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv4): Sequential(\n",
      "    (0): Conv1d(48, 48, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool1d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (output): Linear(in_features=1248, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define the network\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels=22,\n",
    "                out_channels=22,\n",
    "                kernel_size=200,# Ceramic nuclear 3 * 3\n",
    "                stride=1,#  \n",
    "                padding=1# Edge padding\n",
    "            ),                               #     ((20,16,840) -> (20, 16, 840)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2)      # Dimension Transformation (20, 16, 840) -> (20, 16, 420)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels=22,\n",
    "                out_channels=32,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1\n",
    "            ),                               #     ((20, 16, 420) -> (20, 32, 420)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2)      #     ((20, 32, 420) -> (20, 32, 210)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels=32,\n",
    "                out_channels=48,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1\n",
    "            ),                               #     ((20, 16, 420) -> (20, 32, 420)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2)      #     ((20, 32, 420) -> (20, 32, 210)\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels=48,\n",
    "                out_channels=48,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1\n",
    "            ),                               #     ((20, 16, 420) -> (20, 32, 420)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=5)      #     ((20, 32, 420) -> (20, 32, 210)\n",
    "        )\n",
    "        self.output = nn.Linear(1248,4)    #   32 * 210 is a number, does not mean that two-dimensional 32 dimensions are multiplied by 210, and the training data changes, this must be changed.\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        # out.view Type to one-dimensional, similar to Flatten in Keras\n",
    "        out = out.view(out.size(0),-1)      #Pytorch's flattening operation is defined in Forward, where the dimension here is 2D 20 * (32 * 210)\n",
    "        out = self.output(out)\n",
    "        return out\n",
    "\n",
    "cnn = CNN()\n",
    "print(cnn)# Print View Network Structure\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c9c051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing to train\n",
    "optimizer = torch.optim.Adam(cnn.parameters(),lr=0.01,)# Use the ADAM optimization algorithm to train\n",
    "loss_func = nn.CrossEntropyLoss()#              \n",
    "for epoch in range(100):\n",
    "    for step ,(b_x,b_y) in enumerate(train_loader):\n",
    "#         print(torch.Tensor(b_x).float().dtype)\n",
    "        output = cnn(b_x)\n",
    "        #b_y must be a long type\n",
    "        # print(b_y)\n",
    "        loss = loss_func(output,b_y.long())\n",
    "\n",
    "        optimizer.zero_grad()#  \n",
    "        loss.backward()\n",
    "        optimizer.step()# Parameter update\n",
    "\n",
    "        if step%20 ==0:\n",
    "            test_output = cnn(torch.tensor(X_test))\n",
    "#             print(test_output.shape)\n",
    "            # .max (a, 1) Returns the maximum value of each row, [1] .data.NumpY (), return the maximum position index\n",
    "            _, pred_y = torch.max(test_output, 1)\n",
    "#             print('pred',pred_y.shape)\n",
    "            pred_y = pred_y.reshape(len(pred_y),1)\n",
    "            y_test1 = y_test.reshape(len(y_test),1)\n",
    "#             print(y_test1.shape)\n",
    "#             print(pred_y.shape)\n",
    "            score = accuracy_score(y_test1, pred_y)\n",
    "            print('Точность на тесте', round(score * 100),'%')\n",
    "            \n",
    "\n",
    "\n",
    "            # accuracy = float((pred_y == np.array(y_test).astype(int).sum()) / float(y_test.size(0)))\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy())\n",
    "            print('finish training')\n",
    "            torch.save(cnn,'cnn_minist.pkl')# Save training good network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "b2d5b76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using training good network prediction\n",
    "# cnn = torch.load('cnn_minist.pkl')\n",
    "\n",
    "# test_output = cnn(test_x[:20])\n",
    "# pred_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "\n",
    "# print(pred_y, 'prediction number')\n",
    "# print(test_y[:20].numpy(), 'real number')\n",
    "\n",
    "# test_output1 = cnn(test_x)\n",
    "# pred_y1 = torch.max(test_output1, 1)[1].data.numpy()\n",
    "# accuracy = float((pred_y1 == test_y.data.numpy()).astype(int).sum()) / float(test_y.size(0))\n",
    "# print('accuracy',accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cb7a34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
